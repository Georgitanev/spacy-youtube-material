{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from spacy import displacy\n",
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gameplan\n",
    "\n",
    "What I want to do is;\n",
    "\n",
    "1. take instances where my matcher agress with my labelling (taking care that i only grab sentences with 1 language in the document, just in case)\n",
    "2. use the matcher to assign the correct labels such that I have a NER datastructure that I can feed to the training loop\n",
    "3. replace the NER in the pipeline with my own one\n",
    "4. train an instance of NER and have a peek at the results\n",
    "\n",
    "The main goal of this part is to explain NER and to get to a working training loop. We will need to iterate on this training loop but this is probably better for another video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1st things 1st \n",
    "\n",
    "I figured it would be good to first focus on what `NER` is. The easiest way to do this is to show that spacy comes with a few detectors from the get-go. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">My name is \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Steve\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " and I was born on \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    24th June 1973\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ".            I work at \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Amsterdam\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ". The contract states that we will            pay $\n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    1000\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       " upfront for the service and \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    20 euro\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       " for every room sold            via your website.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp(\"My name is Steve and I was born on 24th June 1973. \\\n",
    "           I work at Apple in Amsterdam. The contract states that we will \\\n",
    "           pay $1000 upfront for the service and 20 euro for every room sold \\\n",
    "           via your website.\")\n",
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spaCy pipelines\n",
    "\n",
    "![](from-docs.png)\n",
    "\n",
    "You might remember the `NER` from a previous video. We turned it off because our matchers only used the part of speech and dependency features. \n",
    "\n",
    "What we will now do is replace this part of the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger', 'parser', 'ner']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back to the Task at Hand \n",
    "\n",
    "Let's first grab out matcher from before. I've moved the matcher code into a small package to make sure our code-base isn't loosely defined across notebooks (good idea)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "def _create_versioned(name):\n",
    "    return [\n",
    "        [{'LOWER': name}], \n",
    "        [{'LOWER': {'REGEX': f'({name}\\d+\\.?\\d*.?\\d*)'}}], \n",
    "        [{'LOWER': name}, {'TEXT': {'REGEX': '(\\d+\\.?\\d*.?\\d*)'}}],\n",
    "    ]\n",
    "\n",
    "def create_patterns():\n",
    "    # let us first make the patterns with versions \n",
    "    versioned_languages = ['ruby', 'php', 'python', 'perl', 'java', 'haskell', \n",
    "                       'scala', 'c', 'cpp', 'matlab', 'bash', 'delphi']\n",
    "    flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "    versioned_patterns = flatten([_create_versioned(lang) for lang in versioned_languages])\n",
    "    \n",
    "    # next we'll keep a list of non-standard patterns \n",
    "    lang_patterns = [\n",
    "        [{'LOWER': 'objective'},{'IS_PUNCT': True, 'OP': '?'},{'LOWER': 'c'}],\n",
    "        [{'LOWER': 'objectivec'}],\n",
    "        [{'LOWER': 'c'}, {'LOWER': '#'}],\n",
    "        [{'LOWER': 'c'}, {'LOWER': 'sharp'}],\n",
    "        [{'LOWER': 'c#'}],\n",
    "        [{'LOWER': 'f'}, {'LOWER': '#'}],\n",
    "        [{'LOWER': 'f'}, {'LOWER': 'sharp'}],\n",
    "        [{'LOWER': 'f#'}],\n",
    "        [{'LOWER': 'lisp'}],\n",
    "        [{'LOWER': 'common'}, {'LOWER': 'lisp'}],\n",
    "        [{'LOWER': 'go', 'POS': {'NOT_IN': ['VERB']}}],\n",
    "        [{'LOWER': 'golang'}],\n",
    "        [{'LOWER': 'html'}],\n",
    "        [{'LOWER': 'css'}],\n",
    "        [{'LOWER': 'sql'}],\n",
    "        [{'LOWER': {'IN': ['js', 'javascript']}}],\n",
    "        [{'LOWER': 'c++'}]]\n",
    "    \n",
    "    return versioned_patterns + lang_patterns\n",
    "```\n",
    "\n",
    "With our matcher defined, we can load it in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proglang.matcher import create_patterns\n",
    "\n",
    "matcher = Matcher(nlp.vocab, validate=True)\n",
    "matcher.add(\"PROG_LANG\", None, *create_patterns())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can confirm that your matcher does indeed match things we're interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "golang\n",
      "python\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"I am Vincent and I do code with datastuff and golang seems like a cool language but I mostly work in python.\")\n",
    "\n",
    "for idx, start, end in matcher(doc):\n",
    "    print(doc[start:end],)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also confirm that what we match on is a `Span` object. Good to note that a span cannot overlap and neither can a named entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.span.Span"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc[start:end])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing a Doc \n",
    "\n",
    "First I'll need to prepare the data such that it fits the API. Docs found [here](https://spacy.io/usage/training#training-simple-style)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('I am Vincent and I do code with datastuff and golang seems like a cool language but I mostly work in python.',\n",
       " {'entities': [(46, 52, 'PROGLANG'), (101, 107, 'PROGLANG')]})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_train_data(doc):\n",
    "    return (doc.text, {'entities': [(doc[start:end].start_char, doc[start:end].end_char, 'PROGLANG') for idx, start, end in matcher(doc)]})\n",
    "\n",
    "parse_train_data(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is nice. Let's grab some data and train on it. The idea is that I will look at examples where I my excel label overlaps with a matcher that finds a single example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2000,), 416)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = (pd.read_csv(\"have_label.txt\", nrows=5_000, sep='\\t', usecols=['Label', 'Title']))\n",
    "titles = df.loc[lambda d: d['Label'] == 1]['Title']\n",
    "titles = df['Title']\n",
    "titles.shape, sum(1 for d in nlp.pipe(titles) if len(matcher(d)) == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = (parse_train_data(d) for d in nlp.pipe(titles) if len(matcher(d)) == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Deploying SQL Server Databases from Test to Live',\n",
       "  {'entities': [(10, 13, 'PROGLANG')]}),\n",
       " ('Is Windows Server 2008 \"Server Core\" appropriate for a SQL Server instance?',\n",
       "  {'entities': [(55, 58, 'PROGLANG')]}),\n",
       " ('Good STL-like library for C', {'entities': [(26, 27, 'PROGLANG')]}),\n",
       " ('Paging SQL Server 2005 Results', {'entities': [(7, 10, 'PROGLANG')]}),\n",
       " ('MySQL/Apache Error in PHP MySQL query',\n",
       "  {'entities': [(22, 25, 'PROGLANG')]})]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_DATA = [parse_train_data(d) for d in nlp.pipe(titles) if len(matcher(d)) == 1]\n",
    "TRAIN_DATA[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have training data we'll start a new spacy model. \n",
    "\n",
    "![](from-docs.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_blank_nlp():\n",
    "    nlp = spacy.blank(\"en\")\n",
    "    ner = nlp.create_pipe(\"ner\")\n",
    "    nlp.add_pipe(ner, last=True)\n",
    "    ner = nlp.get_pipe(\"ner\")\n",
    "    for _, annotations in TRAIN_DATA:\n",
    "            for ent in annotations.get(\"entities\"):\n",
    "                ner.add_label(ent[2])\n",
    "    return nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.util import minibatch, compounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 171.68839159619745}\n",
      "Losses {'ner': 12.77679905959765}\n",
      "Losses {'ner': 8.576888525372755}\n",
      "Losses {'ner': 7.921659459052945}\n",
      "Losses {'ner': 14.079479234089929}\n",
      "Losses {'ner': 22.2691320396331}\n",
      "Losses {'ner': 1.814979443285463}\n",
      "Losses {'ner': 3.614291375231467}\n",
      "Losses {'ner': 13.192082488298539}\n",
      "Losses {'ner': 13.265022523456754}\n",
      "Losses {'ner': 7.289025678655073}\n",
      "Losses {'ner': 27.61016798911226}\n",
      "Losses {'ner': 7.929718542739575}\n",
      "Losses {'ner': 12.558411253964168}\n",
      "Losses {'ner': 6.295474202151618}\n",
      "Losses {'ner': 0.0010332701030309791}\n",
      "Losses {'ner': 2.9600180028579797e-05}\n",
      "Losses {'ner': 6.542552724515043e-07}\n",
      "Losses {'ner': 3.88690716435697e-10}\n",
      "Losses {'ner': 3.078534097405294e-10}\n"
     ]
    }
   ],
   "source": [
    "nlp = create_blank_nlp()\n",
    "optimizer = nlp.begin_training()  \n",
    "for i in range(20):\n",
    "    random.shuffle(TRAIN_DATA)\n",
    "    losses = {}\n",
    "    for text, annotations in TRAIN_DATA:\n",
    "        nlp.update([text], [annotations], sgd=optimizer, losses=losses)\n",
    "    print(f\"Losses at iteration {i}\", losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">I like coding in \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    python\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PROGLANG</span>\n",
       "</mark>\n",
       ", java script, go and rust</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp(\"I like coding in python, java script, go and rust\")\n",
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">I like coding in \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    go\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PROGLANG</span>\n",
       "</mark>\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp(\"I like coding in go\")\n",
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mhmm ... not perfect.\n",
    "\n",
    "## Different Train Loop\n",
    "\n",
    "Here's another run that has more bells and whistles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=9.656993702075896: 100%|██████████| 25/25 [00:56<00:00,  2.52s/it]     \n"
     ]
    }
   ],
   "source": [
    "nlp = create_blank_nlp()\n",
    "optimizer = nlp.begin_training()\n",
    "pbar = tqdm.tqdm(range(25))\n",
    "for i in pbar:\n",
    "    losses = {}\n",
    "    batches = minibatch(TRAIN_DATA, size=compounding(4.0, 32.0, 1.001))\n",
    "    for batch in batches:\n",
    "        texts, annotations = zip(*batch)\n",
    "        nlp.update(\n",
    "            texts,  # batch of texts\n",
    "            annotations,  # batch of annotations\n",
    "            drop=0.1,  # dropout - make it harder to memorise data\n",
    "            losses=losses,\n",
    "        )\n",
    "    pbar.set_description(f\"loss={losses['ner']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">I like coding in \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    python\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PROGLANG</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    java\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PROGLANG</span>\n",
       "</mark>\n",
       " script, \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    go\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PROGLANG</span>\n",
       "</mark>\n",
       " and rust</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp(\"I like coding in python, java script, go and rust\")\n",
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">I like coding in \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    go\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PROGLANG</span>\n",
       "</mark>\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp(\"I like coding in go\")\n",
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is also not perfect. So we'll need to do some iterations of improvement. But there's a lot to cover there and that is for the next video.\n",
    "\n",
    "## Final Thoughts \n",
    "\n",
    "It feels like explaining entities and setting up a training loop might be enough for a single video. Talking about all the things one could tweak during a training loop might be worth a seperate video. It also feels like there will be a phase of 'label some more and set up a proper evaluation pipeline' which might also be good to have in a seperate video. I'm also getting a feeling that it's gonna get mighty convenient if I could use prodigy here.\n",
    "\n",
    "Thoughts? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en import English\n",
    "from spacy.pipeline import EntityRuler\n",
    "\n",
    "nlp = English()\n",
    "ruler = EntityRuler(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruler.add_patterns([{'label':'PROGLANG', 'pattern': p} for p in create_patterns()])\n",
    "nlp.add_pipe(ruler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.to_disk('entity-ruler')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">I am Vincent and I like to code in \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    go\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PROGLANG</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    python\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PROGLANG</span>\n",
       "</mark>\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(nlp(\"I am Vincent and I like to code in go and python\"), 'ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = (d for d in nlp.pipe(df['Title']) if len(d.ents) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(How can I Java webstart multiple, dependent, native libraries?, (Java,))"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo = next(g)\n",
    "foo, foo.ents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's move this into a text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (pd.read_csv(\"Questions.csv\", nrows=1_000_000, \n",
    "                  encoding=\"ISO-8859-1\", usecols=['Title', 'Id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "322057"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = pathlib.Path(\"./proglang-text.jsonl\").resolve()\n",
    "txt = \"\"\n",
    "for i in range(5000):\n",
    "    txt += json.dumps({\"text\": df['Title'][i]}) + '\\n'\n",
    "    \n",
    "p.write_text(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcli\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlang\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model language'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'positional'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0;32mclass\u001b[0m \u001b[0;34m'str'\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0moutput_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Output directory to store model in'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'positional'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0;32mclass\u001b[0m \u001b[0;34m'pathlib.Path'\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtrain_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Location of JSON-formatted training data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'positional'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0;32mclass\u001b[0m \u001b[0;34m'pathlib.Path'\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdev_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Location of JSON-formatted development data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'positional'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0;32mclass\u001b[0m \u001b[0;34m'pathlib.Path'\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mraw_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Path to jsonl file with unlabelled text documents.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'option'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0;32mclass\u001b[0m \u001b[0;34m'pathlib.Path'\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbase_model\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Name of model to update (optional)'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'option'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0;32mclass\u001b[0m \u001b[0;34m'str'\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpipeline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Comma-separated names of pipeline components'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'option'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'p'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0;32mclass\u001b[0m \u001b[0;34m'str'\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tagger,parser,ner'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvectors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model to load vectors from'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'option'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'v'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0;32mclass\u001b[0m \u001b[0;34m'str'\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Number of iterations'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'option'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0;32mclass\u001b[0m \u001b[0;34m'int'\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_early_stopping\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Maximum number of training epochs without dev accuracy improvement'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'option'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ne'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0;32mclass\u001b[0m \u001b[0;34m'int'\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_examples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Number of examples'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'option'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ns'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0;32mclass\u001b[0m \u001b[0;34m'int'\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0muse_gpu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Use GPU'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'option'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'g'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0;32mclass\u001b[0m \u001b[0;34m'int'\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mversion\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model version'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'option'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'V'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0;32mclass\u001b[0m \u001b[0;34m'str'\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'0.0.0'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmeta_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Optional path to meta.json to use as base.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'option'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0;32mclass\u001b[0m \u001b[0;34m'pathlib.Path'\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0minit_tok2vec\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Path to pretrained weights for the token-to-vector parts of the models. See 'spacy pretrain'. Experimental.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'option'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m't2v'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0;32mclass\u001b[0m \u001b[0;34m'pathlib.Path'\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mparser_multitasks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Side objectives for parser CNN, e.g. 'dep' or 'dep,tag'\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'option'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0;32mclass\u001b[0m \u001b[0;34m'str'\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mentity_multitasks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Side objectives for NER CNN, e.g. 'dep' or 'dep,tag'\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'option'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'et'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0;32mclass\u001b[0m \u001b[0;34m'str'\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnoise_level\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Amount of corruption for data augmentation'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'option'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'nl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0;32mclass\u001b[0m \u001b[0;34m'float'\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0meval_beam_widths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Beam widths to evaluate, e.g. 4,8'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'option'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bw'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0;32mclass\u001b[0m \u001b[0;34m'str'\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mgold_preproc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Use gold preprocessing'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'flag'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'G'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0;32mclass\u001b[0m \u001b[0;34m'bool'\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlearn_tokens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Make parser learn gold-standard tokenization'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'flag'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'T'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0;32mclass\u001b[0m \u001b[0;34m'bool'\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Display more information for debug'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'flag'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'VV'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0;32mclass\u001b[0m \u001b[0;34m'bool'\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Run data diagnostics before training'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'flag'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'D'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0;32mclass\u001b[0m \u001b[0;34m'bool'\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Train or update a spaCy model. Requires data to be formatted in spaCy's\n",
       "JSON format. To convert data from other formats, use the `spacy convert`\n",
       "command.\n",
       "\u001b[0;31mFile:\u001b[0m      ~/Development/spacy-course/venv/lib/python3.6/site-packages/spacy/cli/train.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "?spacy.cli.train\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
